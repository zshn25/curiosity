{
  
    
        "post0": {
            "title": "The purpose in life",
            "content": "During hard times it’s difficult to remember the motivation of getting by. We ask ourselves, in the grand scheme of things, does anything matter? . It is easy to go down the rabbit hole thinking nothing matters, after all we are an extremely tiny part of the whole universe existing for an extremely tiny amount of time. How can what we as individuals may do be of any importance? . . Fig.1: If time was scaled down to 1 year, human life is a blink of an eye 0.23s. By Efbrazil, CC BY-SA 3.0 , via Wikimedia Commons. Click to see a similar interactive infographic for space . For such times, this post is a reminder that in the grand scheme of things, we may as well not be of great importance but what if we’re wrong? What if we are the only hope of the universe. What if the universe has waited for all these billions of years just to produce something as complicated as us humans. What if we are one of the most important things that matters in the entire universe. . Beyond self . This is also a reminder to take in other perspectives. Yes, in the dimensions of space and time, we are just a tiny microscopic blip. But, in the realm of ideas and value, we are highly significant. We have made extremely huge progress in our understanding of nature and our abilities to build and craft tools using this knowledge which we could have never imagined. All of which wouldn’t have been possible without generations and generations of tiny little steps towards progress. Of course the person who played his part in making these steps would think that in the grand scheme of things he doesn’t matter but we know that he does. We all need to play our part. We are a part of this universe. We may as well be finite but the work we do to make progress may not be. . Such perspectives can be hard to come in western societies because of the heavy focus on self. Once we let go of our ego, we realize that we are a part of the universe and the present. We essentially make the universe meaningful. We may be powerless mortal beings but we have this connection to the eternal. And then, we realize the answer to the question, “what is the purpose of life?” The purpose of is to live. To play our part. By just existing. . My purpose . I believe that the purpose of life is to pass information. Living beings (including viruses) do this using our DNA. Via evolution, newer generations adapt to the ever changing environment, giving them an advantage to sustain themselves. Humans are special in this regard as we also have other means of transferring information which is much more efficient. Recent advances in technology have enabled us to communicate and share knowledge in an unprecedented way. Although we as individuals are mortal, ideas are immortal, and by passing knowledge, we progress. The meaning of life for me is enabling this advancement. . I ultimately find purpose in my curiosity. It enables me to learn as much as I can, to explore and discover the unknown, to expand ideas, to seek answers, to invent and create solutions, to inspire others, to fail, to get humiliated and to repeat. In the process, I can share my experiences with others and there-by transfer knowledge. . Live as if you were to die tomorrow. Learn as if you were to live forever. . Mahatma Gandhi . A generalization of this idea is not only the transfer of knowledge to others but just being helpful to others in any form. By being in service in any way to others (which also includes knowledge transfer as a service), we become immortal. . Disclaimer: Formal definitions and philosophies of the meaning of life are out of scope of this post. I may later expand this topic here. .",
            "url": "https://zshn25.github.io/purpose/",
            "relUrl": "/purpose/",
            "date": " • Jun 14, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "A minimal working example of a custom Vector class in C++",
            "content": "This post describes my minimum working implementation of a Vector class in C++, similar to the one from standard library’s std::vector but with only required functionality. The objective is to implement a generic array of dynamic size, i.e. which grows in size as new data gets added to it. We need at least 2 variables to keep track of the capacity of the array and the current index (which is also the size of the data available in the array). We also need a way to access these variables. . class Vector { size_t capacity_ = 0; // current memory capacity size_t curr_idx_ = 0; // current vector size (same as numel) public: size_t size() const {return curr_idx_;} // returns current size of our vector size_t capacity() const {return capacity_;} // returns current capacity of our vector }; . Indexing the vector . We store a pointer to the first element of the array. With this, we can access every element of the array up to it’s size. The pointer to the first element will be a private member. So, we also need a way to access the vector’s elements for read and write purposes. . In order to access the vector’s individual elements, we need a method to index the vector. This indexing method will be used for both reading and writing the vector’s elements. We define an operator[] which returns the element’s reference as follows . template&lt;class T&gt; class Vector { T* vector_ = nullptr; // pointer to first data element size_t capacity_ = 0; // current memory capacity size_t curr_idx_ = 0; // current vector size (same as numel) public: // ... //same as above // Element read/write access T&amp; operator[](const size_t index); // return element reference at index }; //// Definitions // Element read/write access template&lt;class T&gt; T&amp; Vector&lt;T&gt;::operator[](const size_t index) { if (index &gt;= curr_idx_) throw std::invalid_argument(&quot;Index must be less than vector&#39;s size&quot;); return vector_[index]; } . We need to allocate a dynamic memory using new[], which reserves the input amount of memory for our array. . Dynamic allocation of memory means we also need to free the memory manually upon destruction. . template&lt;class T&gt; class Vector { T* vector_ = nullptr; // pointer to first data element size_t capacity_ = 0; // current memory capacity size_t curr_idx_ = 0; // current vector size (same as numel) public: // Constructors Vector() = default; // default constructor // Destructor ~Vector() {delete[] vector_;} }; . Rule of 0/3/5: Defining copy constructor and copy assignment . Since we are explicitly defining a destructor for manual memory management, we also need to define the copy constructor and the copy assignment by the rule of 0/3. . template&lt;class T&gt; class Vector { T* vector_ = nullptr; // pointer to first data element size_t capacity_ = 0; // current memory capacity size_t curr_idx_ = 0; // current vector size (same as numel) public: // Constructors Vector() = default; // default constructor Vector(const Vector&lt;T&gt;&amp; another_vector); // copy constructor Vector&lt;T&gt;&amp; operator=(const Vector&lt;T&gt; &amp;); // copy assignment // Destructor ~Vector() {delete[] vector_;} }; . The copy constructor is used to copy an object of the same type. In our case, we need the copy constructor to copy another vector’s elements. Note that when not defined explicitly, the compiler defines a default copy constructor which does not do what we want. So, it is necessary to define a copy constructor . // Declaration same as before //// Definitions // Copy constructor template&lt;class T&gt; Vector&lt;T&gt;::Vector(const Vector&lt;T&gt;&amp; another_vector) { delete[] vector_; // Delete before copying everything from another vector // Copy everything from another vector curr_idx_ = another_vector.size(); capacity_ = another_vector.capacity(); vector_ = new T[capacity_]; for (size_t i=0; i &lt; capacity_; ++i) vector_[i] = another_vector[i]; } . The copy assignment is similar to the copy constructor but is called when the = operator is used, for e.g. Vector vector = another_vector;. The only difference here will be that the copy assignment will return the pointer to the object while the copy constructor doesn’t have to return anything. . // Declaration same as before //// Definitions // Copy assignment template&lt;class T&gt; Vector&lt;T&gt;&amp; Vector&lt;T&gt;::operator=(const Vector&lt;T&gt;&amp; another_vector) { delete[] vector_; // Delete before copying everything from another vector // Copy everything from another vector curr_idx_ = another_vector.size(); capacity_ = another_vector.capacity(); vector_ = new T[capacity_]; for (size_t i=0; i &lt; capacity_; ++i) vector_[i] = another_vector[i]; return *this; } . Adding and removing elements from the vector . We need a way to add elements to our vector. We can define an additional constructor (apart from the default one), which takes capacity as input and allocates memory of the given capacity. We can further extend this constructor to initialize our vector with a default value. . template&lt;class T&gt; class Vector { T* vector_ = nullptr; // pointer to first data element size_t capacity_ = 0; // current memory capacity size_t curr_idx_ = 0; // current vector size (same as numel) public: // Constructors Vector() = default; // default constructor Vector(const Vector&lt;T&gt;&amp; another_vector); // copy constructor Vector&lt;T&gt;&amp; operator=(const Vector&lt;T&gt; &amp;); // copy assignment Vector(size_t capacity, T initial = T{}); // constructor based on capacity and a default value // Destructor ~Vector() {delete[] vector_;} }; //// Definitions template&lt;class T&gt; Vector&lt;T&gt;::Vector(size_t capacity, T initial): capacity_{capacity}, curr_idx_{capacity}, vector_{new T[capacity]{}} // allocate stack and store its pointer { for (size_t i=0; i &lt; capacity; ++i) vector_[i] = initial; // initialize } . The above constructor can be called as follows . Vector&lt;int&gt; vector(10); // initializes a vector with capacity 10 Vector&lt;int&gt; vector_ones(10, 1) // initializes with an initial value . At this point, a minimum working example of a static array is complete. If we also need to make our vector dynamic, we need a way to increase the vector’s capacity if needed. This will be useful if we want to add elements to the array after we initialize it. . Push back and pop methods . Since the goal of our array is to be dynamic, we also need ways to add and remove elements from it after initialization. To add and remove elements from our vector, we define emplace_back and pop methods respectively. The array also needs to increase its capacity if it needs to. For this, we define a private reserve method, which reserves the input amount of memory. . template&lt;class T&gt; class Vector { public: // ... //same as above void emplace_back(const T&amp; element); // pass element by constant reference T pop(); // pops the last element private: // ... // same as above void reserve(const size_t capacity); }; //// Definitions // ... // same as above template&lt;class T&gt; void Vector&lt;T&gt;::emplace_back(const T&amp; element) { // If no cacacity, increase capacity if (curr_idx_ == capacity_) { if (capacity_ == 0) // handing initial when reserve(8); else reserve(capacity_*2); } // Append an element to the array vector_[curr_idx_] = element; curr_idx_++; } template&lt;class T&gt; T Vector&lt;T&gt;::pop() { if (curr_idx_ &gt; 0) // Nothing to pop otherwise { T to_return = vector_[curr_idx_-1]; // store return value before deleting // vector_[curr_idx_-1]-&gt;~T(); // delete from memory curr_idx_--; return to_return; } else throw std::out_of_range(&quot;Nothing to pop&quot;) } . While appending an element to our vector, the emplace_back function will check if the maximum capacity of the array is reached. This is done by comparing the curr_idx_ (size) of our vector with it’s capacity_. If capacity is same as size, then we reserve more memory. We do this inside the reserve function as follows . // Memory allocation template&lt;class T&gt; inline void Vector&lt;T&gt;::reserve(const size_t capacity) { // Handle case when given capacity is less than equal to size. (No need to reallocate) if (capacity &gt; curr_idx_) { // Reserves memory of size capacity for the vector_ T* temp = new T[capacity]; // Move previous elements to this memory for (size_t i=0; i &lt; capacity_; ++i) temp[i] = vector_[i]; delete[] vector_; // Delete old vector capacity_ = capacity; vector_ = temp; // Copy assignment } } . This completes our minimal working example of a vector class. In the next tutorials, we will extend this class to have iterators, a print function and mathematical operators. . Note that this implementation is just a minimal working example and is mainly for learning and educational purposes. The standard library’s vector must be preferred in practice. . . © Zeeshan Khan Suri, . If this article was helpful to you, consider citing . @misc{suri_cpp_vector_class_2021, title={A minimal working example of a custom Vector class in C + +}, url={https://zshn25.github.io/c++-vector-mwe-tutorial/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={June}} .",
            "url": "https://zshn25.github.io/c++-vector-mwe-tutorial/",
            "relUrl": "/c++-vector-mwe-tutorial/",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Privacy",
            "content": ". This post is still in draft mode. Some of the ideas are complete but needs expansion. Suggestions and comments are always welcome It is often important and helpful to formally define what we are talking about for everyone to be on the same page. Privacy is the ability to choose to express oneself selectively. It is the subtle distinction between what is morally acceptable between the bedroom, the bathroom, the dining table and the street. There are often things that we share with our friends/family over dinner which we would rather not share in public. Or, there might be things in our minds we would be embarrassed and even guilty to share with anyone else. This subtle distinction, when crossed could lead to undesirable consequences. For example, we would be okay finding ourselves naked in a shower but the same in a public place would be obnoxious. . This post is mostly about “digital privacy” and is used interchangeably. It is privacy in the digital age. Where technology and internet have made it extremely easy to infringe the our privacy. I will argue why we should care about our privacy, how (and by whom) it is being infringed, and what can you do about it. . Diving in topics such as this are like going down a never ending rabbit hole. I will be customarily expanding this post with new ideas and methods(of protecting oneself from being exploited) in the future but takes considerable amount time. I feel myself responsible to educate myself and in the process, share it with you here. While it is not obligatory, your support might definitely be helpful. The Why! Why should you care? . Most people ask me why they should care about their own privacy. It’s not like they have anything to hide. By definition (see above), this argument is flawed. Everyone has things to hide. The real question is from whom? As, things that we are okay with sharing with our beloved ones, we might not be willing to share with others. For example, nobody would agree to keep their houses unlocked (for others to come in and see), just because we have nothing to hide or you’re doing nothing wrong. You already care. . You might have nothing to hide, but you have something to fear . Most people do not realize the consequences of sharing things online or just allowing applications to access their information. If you are worried of keeping your house unlocked, you should as well be worried to let others into your life through your virtual windows. Applications are constantly tracking every single activity you do online. From, exactly how many milliseconds you look at a post, where exactly do you look on a picture, to how fast do you scroll through a post. Your every single interaction imaginable is being tracked by almost every modern application and is being stored permanently linking it to you. More of this is the How is your online privacy getting infringed section. . You might be taken out of context or misinterpreted . If one would give me six lines written by the hand of the most honest man, I would find something in them to have him hanged. . -Cardinal Richelieu . Privacy protects us from those who can misinterpret what we say, from those who maliciously want to harm us and from the powerful who want to abuse their power over us. Your personal preferences such as which flavor or ice cream you like might definitely be harmless but your political/religious believes could be used against you. You might be denied access to services, for example, your bank might deny you credit because you You might be denied from entering certain countries. . I need privacy, not because my actions are questionable, but because your judgement and intentions are. . Right to privacy . If you think privacy is unimportant for you because you have nothing to hide, you might as well say free speech is unimportant for you because you have nothing useful to say. . -Edward Snowden . Privacy speaks freedom . Humans are social beings. We care about what others think of us. We try to adjust our behavior depending on the social norms and others’ feedback. Imagine yourself in the middle of a busy street full of people. Would you be as free as you would be in your house all by yourself? Probably not. Not only humans change their behavior in others presence but also the possibility of someone being present changes our behavior. You are your true self when nobody’s looking and nobody could be looking; because you have the freedom to be so. You don’t have to constantly adjust yourself in the fear of being judged. . Privacy brings freedom. I am free to have my life private, to have a pay where I can go and be free of the judgmental eyes. I am free to allow whomever I want (or no one at all) to monitor me. To be able to live freely as if no one is looking. To be my true self. . That freedom is taken away when privacy is taken away ( for e.g., via surveillance). Institutions want to be in control and the most effective way of being in control is to take away freedom. To force compliance of social norms and orthodoxy. To brainwash the members into believing what they want them to believe. . . Freedom as a virtue, frees one from the social norms and orthodoxies and nourishes creative open thinking Freedom is not worth having if it does not include freedom of making mistakes. . Mahatma Gandhi . End-to-end encryption is not enough . The content of your messages or calls might be unnessary for companies to track you. Metadata such as who you’re talking to, when, from where, for how long, etc are enough for companies. Researchers found that just a smartphone’s accelerometer data can reveal people’s location, passwords, body features, age, gender, level of intoxication, driving style, and can be used to reconstruct words spoken next to the device. Services like WhatsApp recently realized that people started to care about privacy and started to advertise their End-toEnd encrytion . How is your online privacy getting infringed . You are being tracked . We rely on various social media and other applications for our everyday life. But do you know that these applications are tracking every single activity you do not only when the application is running but all the time? Most of these applications such as Facebook are free to users. But then how come the company is worth billions of dollars? What do they actually sell? . All 533,000,000 Facebook records were just leaked for free.This means that if you have a Facebook account, it is extremely likely the phone number used for the account was leaked.I have yet to see Facebook acknowledging this absolute negligence of your data. https://t.co/ysGCPZm5U3 pic.twitter.com/nM0Fu4GDY8 . &mdash; Alon Gal (Under the Breach) (@UnderTheBreach) April 3, 2021 A recent leak of Facebook’s database allows the private data to be misused by malicious indented actors 1. . Political propaganda . Nobody needs to justify why they “need” a right: the burden of justification falls on the one seeking to infringe upon the right. . -Edward Snowden . It is one thing that your Google search on . The world is full of ill-intended malicious people who wouldn’t mind destroying someone else’s life for their own benefit. All it takes is one mistake from innocent people being in the wrong place at the wrong time to screw them over. . Microsoft reports that 75 percent of U.S. recruiters and human-resource professionals now do online research about candidates, often using information provided by search engines, social-networking sites, photo/video-sharing sites, personal web sites and blogs, and Twitter. They also report that 70 percent of U.S. recruiters have rejected candidates based on internet information. . Source . Your information may be used against you by your government in order to gain political power. Think about the social credit system. It is already being practiced in some countries. For e.g., let’s say your country implements it and starts surveilling on you 24x7 and as an open-minded individual, you enter a discussion with your peers and talk against some things your government has done recently. There is a good chance that because once-upon-a-time you raised your voice against the government, you are denied flight tickets for your next vacation. . This again brings up my point on personal freedom. Privacy speaks freedom. The ability to criticize the government is the exact thing that keeps them in check. Taking away that ability by penalizing free speech takes away our freedom and restricts us . What can you do about it? . Governments approve surveillance programs citing anti-terrorism and the question arises “security versus privacy”. Schneier argues that the real question should be liberty versus control2. He argues that foreign physical threat is as bad as … . The privacy paradox . Many people are indeed concerned about their privacy but behave as they didn’t. This is known as the privacy paradox. . Humans are social beings and we seek others’ approval. We have a need for others to know what we are doing, which is why we voluntarily publish information about us online. But as social beings, we also need to acknowledge that there are things which let our close ones, our psychologists, our physicians, our lawyers to know about us which we would never be willing others know. People easily say they don’t value privacy while their actions negate their belief. . Other reasons for the privacy paradox might be “finding it technologically difficult to take certain actions that disallow institutions to take advantage of it. Applications are purposefully designed to make it as difficult for a regular user as possible to care about their privacy by changing the default settings, which are often extracting as much of user’s personal data as possible. Most users do not have the knowledge and experience to protect themselves. . Who ? Government (5 eyes) Companies . Choose companies and services that are interested in their users’ privacy and take measures to advocate it. This website gives great alternatives to the daily applications we use everyday. . What can you do? . Use encryption everywhere . How Strong Encryption Can Help Avoid Online Surveillance | Install https://www.eff.org/https-everywhere browser plugin | Change your default search engine to Duckduckgo on all browsers and start using it. | Avoid platforms which are notorious for privacy abuse. | Use Tor. Tor uses decentralized. | Tip: Use temp mail | Use OpenSource software. You can find opensource alternatives to almost every software. One example is Signal over Whatsapp | Visit privacytools.io and find alternatives to your everyday software. | Use tools like PrivacyBadger and UBlock Origin to block Ads and other stuff. | Encourage your friends and family to join the privacy preserving social media | . Extreme: . Use Qubes OS with Whonix virtual machine (VM) which routes all your network traffic through Tor. Qubes can also sandbox applications in their own VM so that the application does not affect anything else outside their own sandbox VM. If you don’t want to install the complete OS, you can also use Whonix VM seperately. | Setup matrix network on your own server for secure, decentralized communication . Follow this guide | https://chrome.google.com/webstore/detail/google-analytics-opt-out/fllaojicojecljbmefodhfapmkghcbnh/related?hl=en | . Closing thoughts . Book recommendation . To summarize, I would like to point you to the following TED talk which will hopefully fill-in the gaps I left unfilled. . References . 533 million Facebook users’ phone numbers and personal data have been leaked online &#8617; . | The Eternal Value of Privacy &#8617; . |",
            "url": "https://zshn25.github.io/why-privacy-matters/",
            "relUrl": "/why-privacy-matters/",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Layers fusion for faster neural network inference",
            "content": "In the previous post, we proved that convolutions are linear. There are other linear layers in a neural network such as a batch normalization layer. A batch normalization layer normalizes its input batch to have zero mean and unit standard deviation, which are calculated from the input batch.1 It basically translates/shifts and scales the input batch, thus being a linear operation. In many network architectures such as ResNets2 and DenseNets3, a convolutional layer followed by a batch norm layer is used. . During training, the mean and standard deviation of the input batch are used in the batch normalization and are eventually learnt. During inference, these estimates of mean and standard deviation are used instead. The idea of this post is to fuse these two consecutive layers during inference, thereby reducing computation and thus inference time. . Note that this must not be done during training since the input batch&#39;s mean and standard deviation are not yet learnt and fusing before training will be same as removing the batch normalization completely. . Pytorch provides a utility function to fuse convolution and batch norm, although this was meant for the use of quantization. In this post, I share the following function to recursively check and fuse all consecutive convolution and batch norm layers. . from torch import nn from torch.nn.utils.fusion import fuse_conv_bn_eval def fuse_all_conv_bn(model): &quot;&quot;&quot; Fuses all consecutive Conv2d and BatchNorm2d layers. License: Copyright Zeeshan Khan Suri, CC BY-NC 4.0 &quot;&quot;&quot; stack = [] for name, module in model.named_children(): # immediate children if list(module.named_children()): # is not empty (not a leaf) fuse_all_conv_bn(module) if isinstance(module, nn.BatchNorm2d): if isinstance(stack[-1][1], nn.Conv2d): setattr(model, stack[-1][0], fuse_conv_bn_eval(stack[-1][1], module)) setattr(model, name, nn.Identity()) else: stack.append((name, module)) . Test . Fusing all convolution and batch norm layers of ResNet101 makes the resulting model ~25% faster with negligible difference in the model&#39;s output. . import torch from torchvision.models.resnet import resnet101 model=resnet101(pretrained=True).to(&#39;cuda&#39;) model.eval() rand_input = torch.randn((1,3,256,256)).to(&#39;cuda&#39;) # Forward pass output = model(rand_input) print(&quot;Inference time before fusion:&quot;) %timeit model(rand_input) # Fuse Conv BN fuse_all_conv_bn(model) print(&quot; nInference time after fusion:&quot;) %timeit model(rand_input) # compare result print(&quot; nError between outputs before and after fusion:&quot;) torch.norm(torch.abs(output - model(rand_input))).data . . Inference time before fusion: 43.4 ms ± 17.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) Inference time after fusion: 31.2 ms ± 7.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) Error between outputs before and after fusion: . tensor(3.5947e-05, device=&#39;cuda:0&#39;) . Note that the same can be done with any network with 2 or more consecutive linear layers to reduce inference time. . © Zeeshan Khan Suri, . If this article was helpful to you, consider citing . @misc{suri_Layers-fusion-for-faster-inference_2021, title={Layers fusion for faster neural network inference}, url={https://zshn25.github.io/Layers-fusion-for-faster-inference/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={Apr}} . References . 1. Ioffe, S. &amp; Szegedy, C.. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. Proceedings of the 32nd International Conference on Machine Learning, in Proceedings of Machine Learning Research 37:448-456 Link.↩ . 2. K. He, X. Zhang, S. Ren and J. Sun, &quot;Deep Residual Learning for Image Recognition,&quot; 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90. ↩ . 3. G. Huang, Z. Liu, L. Van Der Maaten and K. Q. Weinberger, &quot;Densely Connected Convolutional Networks,&quot; 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2261-2269, doi: 10.1109/CVPR.2017.243. ↩ .",
            "url": "https://zshn25.github.io/Layers-fusion-for-faster-inference/",
            "relUrl": "/Layers-fusion-for-faster-inference/",
            "date": " • Apr 27, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "The virtue of fasting during Ramadan",
            "content": "In order to maintain economic equality and fairness in society, wealth needs to flow from the wealthy to the unfortunate. But often times, wealthy people do not understand the hardships of the poor, not because they are bad but simply because they haven’t experienced what it feels like to be poor. In order to experience this, Muslims are required to give up their worldly conveniences and step in the shoe of a poor person. During the month of Ramadan, practitioners are required to abstain from food, water, bad speech and sex from dawn till dusk.1 Fasting during Ramadan teaches Muslims self-control, discipline, sacrifice, empathy and compassion for the less fortunate and encourages generosity towards the poor. Most Muslims donate a percentage of their income as the obligatory tax (Zakāt) to the poor.2 Ramadan also encourages Muslims to devote time away from worldly activities into devotion and worship by rewarding greater than usual good deeds. Both fasting during Ramadan and charity (per year) are two of the five pillars of Islam and are necessary.3. . I think fasting is a great practice for exercising self-control, sacrifice and compassion towards the poor. Accompanying it with charity makes it a great custom for everyone (not only Muslims) to follow . https://en.wikipedia.org/wiki/Ramadan#Fasting &#8617; . | https://en.wikipedia.org/wiki/Zakat &#8617; . | https://en.wikipedia.org/wiki/Five_Pillars_of_Islam &#8617; . |",
            "url": "https://zshn25.github.io/fasting-during-ramadan/",
            "relUrl": "/fasting-during-ramadan/",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Compilation of 3D mesh models",
            "content": "A compilation of 3D mesh models found on the web for research purposes. . Disclaimer: All images shown here are the sole property of their respective owners. I do not claim any authority over them. . ABC Dataset, 2019 . . Random examples from the dataset. Most models are mechanical parts with sharp edges and well defined surfaces . | SHREC’19, Shape Correspondence with Isometric and Non-Isometric Deformations, 2019 . . | SHREC’19, Correspondence in Humans with Different Connectivity, 2019 . . | Pix3D, 2018 . . | Morgan McGuire, Computer Graphics Archive, 2017 . . | MPII Human Shape . . | GREYC 3D Colored Mesh Database, 2017 . . | Thingi10K, 2017 . . | ObjectNet3D, 2016 . . | ShapeNet, 2016 . . | NIST CAD Models, 2016 . . | Kids with Topological Noise, 2016 . . | A Large Dataset of Object Scans, 2016 . . | TOSCA PARTIAL, 2015 . . | ModelNet, 2015 . . | PASCAL+, 2014 . . | FAUST, 2014 . . | Kids, 2014 . . | Human 3.6, 2014 . . . .   .   | | | | . | Body Models, 2014 . . | Clutter, 2013 . . | IKEA Dataset, 2013 . . . .   .   | | | | .   | | | | . | SHREC’10,’11, 2010, 2011 . . . .   .   | | | | . | A Benchmark for 3D Mesh Segmentation, 2009 . . | TOSCA High-res, 2008 . . | McGill 3D Shape Benchmark, 2008 . . | SHREC’07, Watertight Dataset, 2007 . . | Human Face, 2006 . . | Non-rigid world, 2006 . . | SCAPE, 2004 . . | The Brown Mesh Set, 2004 . . | Mesh Data from Deformation Transfer for Triangle Meshes, 2004 . . . . . .   .   | | | | | | .   | | | | | | . | The Princeton Shape Benchmark, 2003 . | . Other Miscellaneous Data . Keenan’s 3D Model Repository . . . . . . .   .   | | | | | | . | The Utah 3D Animation Repository . . . . . . .   .   | | | | | | | . | The Stanford 3D Scanning Repository . . . . . . .   .   | | | | | | | . | Killeroo 3D Scan . . | Cyberware Whole Body Scans . . . . . .   .   | | | | | | . | MPI Informatics Building Model . . | Cornell Box . . | NASA 3D Model Repo . . . . . . .   .   | | | | | | | . | Aim@Shape . | ORCA: Open Research Content Archive . . . . .   .   | | | | | . | MorphoSource . . | Procedurally Generated Random Objects . . | . Other compilations . Wikipedia - List_of_common_3D_test_models . | Aim@Shape Links . | Level of Detail for 3D Graphics . | Point Cloud Library Dataset . | Yulan Guo’s website . | .",
            "url": "https://zshn25.github.io/compilation-3d-mesh-resources/",
            "relUrl": "/compilation-3d-mesh-resources/",
            "date": " • Apr 14, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Practicing Gratitude",
            "content": "I believe that most of us belong somewhere in the middle of this bell curve, which approximates how fortunate (in terms of many factors) people are. On one extreme are people who were born in extreme poverty without basic necessities, or with crippling physical and mental disabilities or during times of warfare and crisis or belonging to races/regions with extreme discrimination and injustice or have unfortunately undergone negative and life changing tragedies. On the other hand are the fortunate, with extreme amounts of wealth, health, freedom, luck, etc.. While most of us belong somewhere in the middle, we often question why are we not fortunate enough to be born in the richest, socially elite and forget than while belonging to the normal also means not belonging to the negative side. . . My hypothesis on how fortunate we are. X-axis: How fortunate we are. Y-axis: Population. Image by D Wells, CC BY-SA 4.0, via Wikimedia Commons. . This post is a reminder that while it’s not perfect, we should be grateful of being fortunate enough of not belonging to the extreme negative side. Let’s be grateful of our basic needs being fulfilled, of having access to food, clean water and shelter. Let’s be grateful to be born during such prosperous times with little conflicts and epidemics (except Covid-19). Let’s be grateful for having people who love and care for us, for the sacrifices many have suffered for our freedom and liberty to be who we want to be, to learn what we want to learn with access to unprecedented amount of knowledge the world has gathered for us and being able to live in the wonderful times where our personal freedoms are respected, where practicing equality is promoted and spreading of discrimination and hate is frowned upon. Let’s be grateful for being physically and mentally healthy without major disabilities and immediate access to world class healthcare and to not have undergone life crippling accidents/tragedies. Let’s be grateful for the world changing innovations happening in all fields every day. Let’s be grateful for this beautiful normal life. .",
            "url": "https://zshn25.github.io/practicing-gratitude/",
            "relUrl": "/practicing-gratitude/",
            "date": " • Apr 11, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Dihydrogen Monoxide - The Truth",
            "content": "Dihydrogen monoxide: . is also known as hydroxyl acid, and is the major component of acid rain. | contributes to the “greenhouse effect”. | may cause severe burns. | contributes to the erosion of our natural landscape. | accelerates corrosion and rusting of many metals. | may cause electrical failures and decreased effectiveness of automobile brakes. | has been found in excised tumors of terminal cancer patients. | . Despite the danger, dihydrogen monoxide is often used: . as an industrial solvent and coolant. | in nuclear power plants. | in the production of styrofoam. | as a fire retardant. | in many forms of cruel animal research. | in the distribution of pesticides. Even after washing, produce remains contaminated by this chemical. | as an additive in certain “junk-foods” and other food products. . Coalition to ban DHMO by Jackson, Craig . | . P.S. . April fool .",
            "url": "https://zshn25.github.io/dihydrogen-monoxide/",
            "relUrl": "/dihydrogen-monoxide/",
            "date": " • Apr 1, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Is convolution linear?",
            "content": "Discrete convolutions are characterized as matrix multiplications and are thus able to execute really fast on GPUs. But, how are they characterized as matrix multiplications? Are convolutions linear? Let’s find out. . 1. Definitions: . 1.1 Convolution . Let $f,g$ be two real valued functions in 1D $f,g : mathbb{R} to mathbb{R} $, the convolution of $f$ with $g$ is defined as . $f * g = displaystyle int_{ mathbb{R}} ! f(t) g(x-t) , mathrm{d}t$ . An example of the 1D convolution of a box function with itself can be seen in the example below . Convolution of a box function with itself. By Brian Amberg derivative work: Tinos, CC BY-SA 3.0. . 1.2 Linearity . Let $K$ be a mapping $K : A to B $ of two vector spaces $A,B$. Such a mapping is linear if . $K( alpha x+ beta y) = alpha K(x)+ beta K(y) $ . for all $ x in A, y in B$ and scalars $ alpha , beta in mathbb{R}$. . In simple words, a linear mapping/transformation preserves vector addition and scalar multiplication. It doesn’t matter whether the linear mapping is applied before or after vector addition and scalar multiplication. . . 2. Linearity of Convolution . To show that convolution is linear, for $ x,y,f : mathbb{R} to mathbb{R}, alpha , beta in mathbb{R}$, we need to prove . $( alpha x + beta y) * f stackrel{!}{=} alpha (x * f) + beta (y * f)$ . 2.1 Proof . (αx+βy)∗f=∫R ⁣(αx(t)+βy(t))f(x−t) dt=∫R ⁣(αx(t)f(x−t)+βy(t)f(x−t)) dt=α∫R ⁣x(t)f(x−t) dt+β∫R ⁣y(t)f(x−t) dt(Linearity of integral)=α(x∗f)+β(y∗f) large{ begin{aligned} ( alpha x + beta y) * f &amp;= int_{ mathbb{R}} ! ( alpha x(t) + beta y(t)) f(x-t) , mathrm{d}t &amp;= int_{ mathbb{R}} ! ( alpha x(t)f(x-t) + beta y(t)f(x-t)) , mathrm{d}t &amp;= alpha int_{ mathbb{R}} ! x(t)f(x-t) , mathrm{d}t + beta int_{ mathbb{R}} ! y(t)f(x-t) , mathrm{d}t quad text{(Linearity of integral)} &amp;= alpha( x * f) + beta( y * f) end{aligned} }(αx+βy)∗f​=∫R​(αx(t)+βy(t))f(x−t)dt=∫R​(αx(t)f(x−t)+βy(t)f(x−t))dt=α∫R​x(t)f(x−t)dt+β∫R​y(t)f(x−t)dt(Linearity of integral)=α(x∗f)+β(y∗f)​ . proves that convolution is a linear operator. This proof directly follows from that fact that an integral is a linear mapping of real-valued (integrable) functions to $ mathbb{R}$. . $ small{ displaystyle int_a^b{[{c_1}{f_1}(x)+{c_2}{f_2}(x)+ cdots +{c_n}{f_n}(x)]dx}={c_1} displaystyle int_a^b{f_1(x)dx}+{c_2} displaystyle int_a^b{f_2(x)dx}+ cdots +{c_n} displaystyle int_a^b{f_n(x)dx}}$ . . 3. Discrete convolution as matrix multiplication . So, if convolutions are linear, we should be able to express the discrete convolution as a matrix multiplication. In fact, one of the input function is converted to a Toeplitz matrix, enabling a discrete convolution to be characterized by a convolution. . y=h∗x=[h10⋯00h2h1⋮⋮h3h2⋯00⋮h3⋯h10hm−1⋮⋱h2h1hmhm−1⋮h20hm⋱hm−2⋮00⋯hm−1hm−2⋮⋮hmhm−1000⋯hm][x1x2x3⋮xn]y = h ast x = begin{bmatrix} h_1 &amp; 0 &amp; cdots &amp; 0 &amp; 0 h_2 &amp; h_1 &amp; &amp; vdots &amp; vdots h_3 &amp; h_2 &amp; cdots &amp; 0 &amp; 0 vdots &amp; h_3 &amp; cdots &amp; h_1 &amp; 0 h_{m-1} &amp; vdots &amp; ddots &amp; h_2 &amp; h_1 h_m &amp; h_{m-1} &amp; &amp; vdots &amp; h_2 0 &amp; h_m &amp; ddots &amp; h_{m-2} &amp; vdots 0 &amp; 0 &amp; cdots &amp; h_{m-1} &amp; h_{m-2} vdots &amp; vdots &amp; &amp; h_m &amp; h_{m-1} 0 &amp; 0 &amp; 0 &amp; cdots &amp; h_m end{bmatrix} begin{bmatrix} x_1 x_2 x_3 vdots x_n end{bmatrix}y=h∗x=⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​h1​h2​h3​⋮hm−1​hm​00⋮0​0h1​h2​h3​⋮hm−1​hm​0⋮0​⋯⋯⋯⋱⋱⋯0​0⋮0h1​h2​⋮hm−2​hm−1​hm​⋯​0⋮00h1​h2​⋮hm−2​hm−1​hm​​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​⎣⎢⎢⎢⎢⎢⎢⎡​x1​x2​x3​⋮xn​​⎦⎥⎥⎥⎥⎥⎥⎤​ – Discrete convoliton using Toeplitz matrix . If this article was helpful to you, consider citing . @misc{suri_is-convolution-linear_2021, title={Is convolution linear?}, url={https://zshn25.github.io/is-convolution-linear/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={Mar}} .",
            "url": "https://zshn25.github.io/is-convolution-linear/",
            "relUrl": "/is-convolution-linear/",
            "date": " • Mar 11, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "ResNet feature pyramid in Pytorch",
            "content": ". Feature Pyramids are features at different resolutions. Since Neural Networks compute features at various levels, (for e.g. the earliest layers of a CNN produce low level features such as Edges and later layers produce higher level features) it would be great to use not only the higher level features but also the previous ones for further processing. . One of the application of such feature pyramid is to be used in an autoencoder architecture with skip connections from encoder to decoder like U-Net. . . In this example, we look at ResNet from Pytorch. ResNet is one of the earliest but also one of the best performing network architectures for various tasks. We inherit the ResNet class and write our own forward method to output a pyramid of feature maps instead. . class ResNetFeatures(ResNet): def __init__(self,**kwargs): super(ResNetFeatures,self).__init__(**kwargs) def _forward_impl(self, x: torch.Tensor) -&gt; List[torch.Tensor]: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x0 = self.relu(x) x = self.maxpool(x0) x1 = self.layer1(x) x2 = self.layer2(x1) x3 = self.layer3(x2) x4 = self.layer4(x3) return [x0,x1,x2,x3,x4] # returns features with channels [64,64,128,256,512] . That&#39;s it. Now, to use it, add it to the source of ResNet. I have made a Gist on how to do this here. Now you can give an argument features_only and it will return the feature pyramid as defined above. . Test code . ## This file is a modified version of [Pytorch&#39;s ResNet](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) and inherits it&#39;s licence. ## License: Copyright Zeeshan Khan Suri, CC BY-NC 4.0 import torch from torch import Tensor import torch.nn as nn try: from torch.hub import load_state_dict_from_url except ImportError: from torch.utils.model_zoo import load_url as load_state_dict_from_url from typing import Type, Any, Callable, Union, List, Optional __all__ = [&#39;ResNet&#39;, &#39;ResNetFeatures&#39;, &#39;resnet18&#39;, &#39;resnet34&#39;, &#39;resnet50&#39;, &#39;resnet101&#39;, &#39;resnet152&#39;, &#39;resnext50_32x4d&#39;, &#39;resnext101_32x8d&#39;, &#39;wide_resnet50_2&#39;, &#39;wide_resnet101_2&#39;] model_urls = { &#39;resnet18&#39;: &#39;https://download.pytorch.org/models/resnet18-5c106cde.pth&#39;, &#39;resnet34&#39;: &#39;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#39;, &#39;resnet50&#39;: &#39;https://download.pytorch.org/models/resnet50-19c8e357.pth&#39;, &#39;resnet101&#39;: &#39;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&#39;, &#39;resnet152&#39;: &#39;https://download.pytorch.org/models/resnet152-b121ed2d.pth&#39;, &#39;resnext50_32x4d&#39;: &#39;https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth&#39;, &#39;resnext101_32x8d&#39;: &#39;https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth&#39;, &#39;wide_resnet50_2&#39;: &#39;https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth&#39;, &#39;wide_resnet101_2&#39;: &#39;https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth&#39;, } def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -&gt; nn.Conv2d: &quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot; return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation) def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -&gt; nn.Conv2d: &quot;&quot;&quot;1x1 convolution&quot;&quot;&quot; return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False) class BasicBlock(nn.Module): expansion: int = 1 def __init__( self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module] = None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(BasicBlock, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d if groups != 1 or base_width != 64: raise ValueError(&#39;BasicBlock only supports groups=1 and base_width=64&#39;) if dilation &gt; 1: raise NotImplementedError(&quot;Dilation &gt; 1 not supported in BasicBlock&quot;) # Both self.conv1 and self.downsample layers downsample the input when stride != 1 self.conv1 = conv3x3(inplanes, planes, stride) self.bn1 = norm_layer(planes) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(planes, planes) self.bn2 = norm_layer(planes) self.downsample = downsample self.stride = stride def forward(self, x: Tensor) -&gt; Tensor: identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = self.relu(out) return out class Bottleneck(nn.Module): # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2) # while original implementation places the stride at the first 1x1 convolution(self.conv1) # according to &quot;Deep residual learning for image recognition&quot;https://arxiv.org/abs/1512.03385. # This variant is also known as ResNet V1.5 and improves accuracy according to # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch. expansion: int = 4 def __init__( self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module] = None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(Bottleneck, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d width = int(planes * (base_width / 64.)) * groups # Both self.conv2 and self.downsample layers downsample the input when stride != 1 self.conv1 = conv1x1(inplanes, width) self.bn1 = norm_layer(width) self.conv2 = conv3x3(width, width, stride, groups, dilation) self.bn2 = norm_layer(width) self.conv3 = conv1x1(width, planes * self.expansion) self.bn3 = norm_layer(planes * self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample self.stride = stride def forward(self, x: Tensor) -&gt; Tensor: identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = self.relu(out) return out class ResNet(nn.Module): def __init__( self, block: Type[Union[BasicBlock, Bottleneck]], layers: List[int], num_classes: int = 1000, zero_init_residual: bool = False, groups: int = 1, width_per_group: int = 64, replace_stride_with_dilation: Optional[List[bool]] = None, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(ResNet, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d self._norm_layer = norm_layer self.inplanes = 64 self.dilation = 1 if replace_stride_with_dilation is None: # each element in the tuple indicates if we should replace # the 2x2 stride with a dilated convolution instead replace_stride_with_dilation = [False, False, False] if len(replace_stride_with_dilation) != 3: raise ValueError(&quot;replace_stride_with_dilation should be None &quot; &quot;or a 3-element tuple, got {}&quot;.format(replace_stride_with_dilation)) self.groups = groups self.base_width = width_per_group self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = norm_layer(self.inplanes) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]) self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]) self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=&#39;fan_out&#39;, nonlinearity=&#39;relu&#39;) elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) # Zero-initialize the last BN in each residual branch, # so that the residual branch starts with zeros, and each residual block behaves like an identity. # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677 if zero_init_residual: for m in self.modules(): if isinstance(m, Bottleneck): nn.init.constant_(m.bn3.weight, 0) # type: ignore[arg-type] elif isinstance(m, BasicBlock): nn.init.constant_(m.bn2.weight, 0) # type: ignore[arg-type] def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int, stride: int = 1, dilate: bool = False) -&gt; nn.Sequential: norm_layer = self._norm_layer downsample = None previous_dilation = self.dilation if dilate: self.dilation *= stride stride = 1 if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion), ) layers = [] layers.append(block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer)) self.inplanes = planes * block.expansion for _ in range(1, blocks): layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer)) return nn.Sequential(*layers) def _forward_impl(self, x: Tensor) -&gt; Tensor: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def forward(self, x: Tensor) -&gt; Tensor: return self._forward_impl(x) class ResNetFeatures(ResNet): def __init__(self,**kwargs): super(ResNetFeatures,self).__init__(**kwargs) def _forward_impl(self, x: torch.Tensor) -&gt; torch.Tensor: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x0 = self.relu(x) x = self.maxpool(x0) x1 = self.layer1(x) x2 = self.layer2(x1) x3 = self.layer3(x2) x4 = self.layer4(x3) return [x0,x1,x2,x3,x4] # returns features with channels [64,64,128,256,512] def _resnet( arch: str, block: Type[Union[BasicBlock, Bottleneck]], layers: List[int], pretrained: bool, progress: bool, features_only = False, **kwargs: Any ): if features_only: model = ResNetFeatures(block=block, layers=layers, **kwargs) else: model = ResNet(block, layers, **kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[arch], progress=progress) model.load_state_dict(state_dict) return model def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-18 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet18&#39;, BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs) def resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-34 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet34&#39;, BasicBlock, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-50 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet50&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-101 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet101&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) def resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-152 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet152&#39;, Bottleneck, [3, 8, 36, 3], pretrained, progress, **kwargs) def resnext50_32x4d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNeXt-50 32x4d model from `&quot;Aggregated Residual Transformation for Deep Neural Networks&quot; &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;groups&#39;] = 32 kwargs[&#39;width_per_group&#39;] = 4 return _resnet(&#39;resnext50_32x4d&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnext101_32x8d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNeXt-101 32x8d model from `&quot;Aggregated Residual Transformation for Deep Neural Networks&quot; &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;groups&#39;] = 32 kwargs[&#39;width_per_group&#39;] = 8 return _resnet(&#39;resnext101_32x8d&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) def wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;Wide ResNet-50-2 model from `&quot;Wide Residual Networks&quot; &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048 channels, and in Wide ResNet-50-2 has 2048-1024-2048. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;width_per_group&#39;] = 64 * 2 return _resnet(&#39;wide_resnet50_2&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def wide_resnet101_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;Wide ResNet-101-2 model from `&quot;Wide Residual Networks&quot; &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048 channels, and in Wide ResNet-50-2 has 2048-1024-2048. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;width_per_group&#39;] = 64 * 2 return _resnet(&#39;wide_resnet101_2&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) . . model = resnet18(pretrained=True, features_only=True) features = model(torch.randn((1,3,265,265))) [print(f.shape) for f in features] . torch.Size([1, 64, 133, 133]) torch.Size([1, 64, 67, 67]) torch.Size([1, 128, 34, 34]) torch.Size([1, 256, 17, 17]) torch.Size([1, 512, 9, 9]) . [None, None, None, None, None] . © Zeeshan Khan Suri, . If this article was helpful to you, consider citing . @misc{suri_ResNet-feature-pyramid-in-Pytorch_2021, title={ResNet feature pyramid in Pytorch}, url={https://zshn25.github.io/ResNet-feature-Pyramid-in-Pytorch/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={Mar}} .",
            "url": "https://zshn25.github.io/ResNet-feature-pyramid-in-Pytorch/",
            "relUrl": "/ResNet-feature-pyramid-in-Pytorch/",
            "date": " • Feb 9, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "$GME short squeeze",
            "content": ". This week (starting 25/01/2021) is an exciting event in the history of stocks, where rare events happening to the GME stock. Although, this might be a definite opportunity to make/lose money, I am in it for the knowledge of how the stock market works. As I am trying to figure out this event and learn more about options trading, I came across this comment which explains things so clearly that I decided to share it here, for my future reference on options knowledge and also to give my readers an insight. . On the question, what is going on with GME, this following comment explains the situation in ELI5 terms . Comment from discussion All right WTF is going on with GME. Many people shorted. To hedge their shorts (since GME is sky-rocketing already), they will need to buy shares. But, since there are only limited shares available, this will drive the price more up, adding more pressure on other short sellers. This cycle repeats and is called the short squeeze. . Some keywords to understand . Shorting or short selling is when you bet your money on the stock declining. You sell shares at the current market price and you believe the share’s value decreases, you’ve sold high. Now, what if you don’t already own any shares? You can borrow shares (from the market), by making the market buy it from you in some future date. Where will you have it in the future? You buy it from the market’s future price (which you believe to be lower than current price) and hence have made money. . Many short sellers have borrowed GME shares, speculating it to crash and sold these borrowed shares to the market. Now, there are only limited shares available and due to heavy short selling, the (borrowed) shares are not actually available. . Companies which have already shorted, (predicted that the stock will go down) but since the opposite is happening (GME has sky rocketed to ATH since people have shorted), the short sellers will buy GME stock to reduce their future losses (or, reduce risk). This is called hedging. . The same user further explains with an example why the market makers (MM) would buy . Comment from discussion All right WTF is going on with GME. What to do? . This is a rare event where normal people like us can coordinate and take money for MM. I do not advice to do anything. Do your own DD, but I have bought some position today at open and hoping the squeeze to happen. Note that short squeeze could take days to happen. And the next question is, when to sell? Very good question. Nobody knows. Depending on your apatite for loss, you can wait for it to truly rocket or take whatever gains without FOMO on future gains. . Edit 1 26/01/2021 . Today we have seen another gamma squeeze where GME rose till $155 (over 100%) but at the end of the day, GME came down, closing at +20%. What drove the price down was believed to be a short ladder attack, where a short seller sells to another short seller and within a short time, the other short seller sells it back. What this does is make people think that other shareholders are selling at lower price, thus creating a havoc and making some of the investors sell at lower price. . GME - How shorts manipulated you, and how you can be better from r/wallstreetbets Edit 27/01/2021 . . Yesterday we have seen yet another gamma squeeze but this time it did not drop back. It was amazing to see GME rise by so much after hours. Maybe it was due to Elon Musk’s tweet? . Gamestonk!! https://t.co/RZtkDzAewJ . &mdash; Elon Musk (@elonmusk) January 26, 2021 The Endgame strategy? . GME Endgame from r/wallstreetbets Final Edit: . GME peaked at $450 as the result of the squeeze. Many brokers including the famous Robinhood in the US halted trading on GME. That means, no one was allowed to buy GME shares anymore. Only selling was allowed. As a result, the price fell from there. Many analysts later said that it GME wouldn’t be halted, it would indeed reach $1000. . . I use Trading212 for buying stocks, which does not charge any commission or any order fee. We both can get a free stock share worth up to €100 if you use the following link to sign up. Do not forget to deposit at least 1€ after signing up. Create a Trading 212 Invest account using this link https://www.trading212.com/invite/FzPJYhiT and we both get a free share! If you already have an account, you can try my Promo Code FzPJYhiT to get a free share. . Disclaimer: This is not a financial advice. Do your own DD before investing. .",
            "url": "https://zshn25.github.io/gme-stock/",
            "relUrl": "/gme-stock/",
            "date": " • Jan 25, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Hot chocolate",
            "content": "I once visited a local Café and ordered Hot Chocolate. Didn’t expect much of it and thought it would be one of those powdered ready-made Cocoa mix. I was pleasantly surprised by how delicious this hot chocolate was. So, I decided to make such hot chocolate myself and looked for recipes. But I couldn’t find any raw Cacao without sugar. The 100% chocolates I could found after a lot of searching are . . Fig. 1: 100% chocolates I found on Amazon but the Sevenhills Cacao Mass is much cheaper. [Disclaimer] . Ingredients . Cacao | Milk | Cream | Spices (Optional) | Orange Zest (Optional) | Sugar or other sweeteners (Optional) | . Recipe . Take around 5 pieces of cacao mass. . . | Add the cacao and heavy cream to a bowl on medium heat. The high fat in the heavy cream makes the Cacao flavor come out . . | Stir with a spoon (preferably wooden to not destroy the non-stick bowl) until it looks like this. At this point you have very thick Keto hot chocolate (more like a pudding) and you can already consume it this way. . . | For the drink, add milk while continuing to stir . . | Add a pinch of Chilli, 3 pinches of Cinnamon powder or one stick, 2 pinches of Cardamom or 2 pods and 3 Cloves. You can also add Orange Zest for a true mulled chocolate feeling. You can also optionally add sugar or any other sweeteners, depending on your taste. . . | Let it simmer on low heat while stirring once in a while. The longer you leave it simmer, the thicker the hot chocolate becomes. . . | Enjoy!! . | Disclaimer: Amazon affiliate links .",
            "url": "https://zshn25.github.io/hot-chocolate/",
            "relUrl": "/hot-chocolate/",
            "date": " • Jan 23, 2021"
        }
        
    
  
    
  
    
        ,"post13": {
            "title": "How to Release on Github",
            "content": "To release on Git, you need to tag a commit first. . Tagging a commit . A tag is a label attached to a specific commit. There are two types of tags . Lightweight | Annotated | . git tag command is used to view all tags in the repo. . Lightweight tag . The lightweight tag is a simple reference to a commit. . git tag &lt;tagname&gt; &lt;commit&gt; creates a lightweight tag. If &lt;commit&gt; is optional and defaults to HEAD. . Example . $ git tag v0.1 HEAD^ # tag the previous commit $ git tag # view all tags v0.1 $ git tag v1.0 # tag the current commit $ git tag # view all tags v0.1 v1.0 . Annotated tag . The annotated tag is a full git object which includes additional (annotated) information such as tag author info, tag date, tag message and tag commit ID. In general, annotated tags are recommended over lightweight . To tag a commit with an annotated tag, use the git tag command with -a option. You must also specify a message using -m option . Example . $ git tag -a -m &quot;feature release 1.0&quot; v1.0 . Pushing tags . git push does not automatically push the tags to remote repository. . To transfer a single tag, use git push &lt;remote&gt; &lt;tagname&gt; | . | To transfer all tags, use git push &lt;remote&gt; --tags | . | . Releases . Once you tag a commit, you can use this to create a release. On GitHub, you can create a release by following this tutorial .",
            "url": "https://zshn25.github.io/how-to-release-on-git/",
            "relUrl": "/how-to-release-on-git/",
            "date": " • Nov 8, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Nutrition",
            "content": "Preventing disease is the first step to long-term health and well-being. By following basic nutrition advice you can improve your health by significant amounts. . . Obesity as a worldwide public health crisis . Western diet is now a major cause of obesity, which is a recognized chronic disease with well-defined health consequences such as Cardiovascular diseases, type 2 diabetes, obstructive sleep apnea, certain types of cancer, osteoarthritis, depression 1. Obesity is labelled by the WHO as a worldwide public health crisis 2. Western diet is normally defined as highly processed foods with very little whole grains, fruits and vegetables. The rate at which obesity is increasing is also increasing at an alarming rate. Data shows that 39% of adults aged 18 years and older were overweight or obese in 20163. . Fig. 1: Obesity is increasing worldwide at an alarming rate. Source . The need to be aware of nutrition in order to avoid obesity and stay healthy now is more than ever. Controlling our food behavior is essential to our long term well being. . Why is obesity increasing? . We are increasingly outsourcing our food preparation. Convenient food has become a norm. These fast-food is often designed as snack-food and marketed to be eaten continuously throughout the day. Such foods are not only less healthy, very high in salt, trans-fat and sugar, but we also tend to overeat them. . This is not an Ad. As seen in the above commercial, nutrient dense foods tend to spoil fast while processed foods usually have very low nutrients in order to increase their shelf life (even pests don’t want to eat processed food). The refining process removes important nutrients such as fiber, iron, B vitamins, in order to increase the food’s shelf life. Their business model is to use the cheapest available raw ingredients, process it as much as possible to increase shelf life and add large amounts salt, fat and sugar to make them seem attractive. . . Focus on food rather than nutrients . We have all been taught that food is made up of 3 macronutrients . Carbohydrates | Proteins | Fats | . Historically, food was a scarce resource. In the animal kingdom, presence of food was unpredictable. So, we evolved to store food in the body for later use. All calories (including proteins, carbs and fats) that aren’t converted into usable energy, ATP, are stored in the body in the form of adipose tissue for later use. This is what we call body fat. It is not necessarily bad to have body fat but if you have excess of body fat, it can lead to severe long term-health issues. . . Fig.2: Obesity and BMI. BruceBlaus, CC BY-SA 4.0, via Wikimedia Commons &lt;/sup&gt; . Is dietary fat really bad? . To address obesity, a lot of focus on reducing saturated fats in diets were made. The processed food industry responded by supplementing fat with sugar to make the food seem more appealing. This also increased the shelf life of foods and so almost every packaged food now comes with enormous amounts of sugar and other sweeteners. This fueled our modern obesity and diabetes. . Despite of an enormous increase in the supply of fat-free foods, obesity rates continued to rise. It is important to know the difference between good and bad fats . The good, the bad, and the ugly . Unsaturated fats, such as Omega-3 fatty acids, which are found in fish and some nuts,seeds, are good for long term health. In fact, Omega-3 fatty acids are the only kinds which cannot be made in human body. So, it is essential to have them. . | Saturated fats are bad for health 4. They increase the amound of bad chelestrol in the blood (LDL). . | While naturally occurring unsaturated fats, such as the ones found in olive oil, avocado, fish and nuts are good, chemically engineered saturated fats, such as the ones found in margarines and frying oils have week chemical bonds and are easily converted into trans-fats 5. Trans fats increase the amount of bad cholesterol in the blood (LDL) and decreases the amount of good cholesterol (HDL), which increases the risk of heart disease 6. These must be avoided as much as possible. . | . Are carbohydrates really bad? . A lot of recent focus has been on the fact that we overconsume carbohydrates. A lot of popular diet trends encourage us to drastically reduce carbs from our diet, even to the extend of avoiding fresh fruits and even grains. At the same time, they seem to suggest that high intake of proteins and fats can be eaten freely. But, a diet with high amounts of animal protein and no whole grains, fruits could leave us with serious problems in the long run. . Carbs has a large variety of foods, some of which are very important for our health, such as brown rice, rolled oats which are rich in fiber; and some are are bad for our health, such as corn-syrup, which has no fiber. In general, the lower the glycemic index (GI) of the carbohydrate, the better. A list of low, medium and bad carbs w.r.t GI is mentioned here. . What about proteins? . All proteins are not created equal. Plant based proteins contain more fiber and less saturated fat than animal based proteins. People who eat lots of plant based diet, have much better health and longevity than people who eat heavy meat diet 7. A diet high in poor quality animal protein, such as processed meat, and high fat cuts, can be harmful to health. Processed meats tend to have very high amounts of sodium, which is a contributor to high blood pressure. . Thinking of food as a whole and not as macronutrients . Categorizing foods into these basic micronutrients may be helpful to study foods but it is not helpful to communicate about them. Food is much more complex than just these macronutrients. So, rather than focusing on nutrients, we should focus on food, because ultimately we don’t eat nutrients but food. . Key takeaways: . The quality of the source of nutrients matters a lot for long term health. . Eat naturally occurring unsaturated fats, such as avocado, olive oil, nuts | low GI carbs with lots of fiber | plant-based proteins. | . | Reduce saturated fats, such as red meat | medium GI carbs with less fiber | animal based proteins. | . | Avoid trans fats, such as oils used for frying in fast food restaurants | refined sugar and carbohydrates with high GI | processed meats | . | . . Exercise . eating --&gt; energy++ excercizing --&gt; energy-- . For people who are trying to lose excess weight, favoring energy expenditure over energy storage needs to be prioritized. This can be achieved by consuming fewer calories and exercising more. . But, not only the quantity of the food, but also the quality of the food we eat matters. . . Summary . When we outsource our food preparation to large companies or restaurants, we get low nutrient dense food. . Nutrient density=nutrients per gramcalories per gram text{Nutrient density} = frac{ text{nutrients per gram}}{ text{calories per gram}}Nutrient density=calories per gramnutrients per gram​ . Home-made food, cooked using high quality ingredients, having natural unsaturated fats, low GI, lots of fiber, and mostly plant-based protein will lead to good long-term health and longevity. The following food pyramid summaries this in a graphical, easy to remember illustration. . . Fig.3: Food pyramid. Spmallare, CC BY 3.0, via Wikimedia Commons . Even if you’re not obese, being aware of the food you eat and maintaining physical exercise will ensure long term health. . . References . https://en.wikipedia.org/wiki/Obesity#Effects_on_health &#8617; . | Hurt RT, Kulisek C, Buchanan LA, McClave SA. The obesity epidemic: challenges, health initiatives, and implications for gastroenterologists. Gastroenterol Hepatol (N Y). 2010;6(12):780-792. &#8617; . | WHO (2018) – Fact sheet – Obesity and overweight. Updated February 2018 &#8617; . | https://en.wikipedia.org/wiki/Fat#Cis_and_trans_fats &#8617; . | https://en.wikipedia.org/wiki/Saturated_fat#Association_with_diseases &#8617; . | https://www.webmd.com/diet/guide/understanding-trans-fats &#8617; . | https://www.health.harvard.edu/blog/eat-more-plants-fewer-animals-2018112915198 &#8617; . |",
            "url": "https://zshn25.github.io/nutrition/",
            "relUrl": "/nutrition/",
            "date": " • Oct 30, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": ":wave: Welcome to Curiosity :tm: . My name is Zeeshan Khan Suri. I believe in life long learning :mortar_board:, I yearn for knowledge :books: and I seek :eyes: the truth :microscope:. In Curiosity, I plan to document :pencil: my journey :roller_coaster: towards this goal :dart:, for that is what that matters in the end :rocket:. Be open minded :haircut_woman:, humble :speak_no_evil: and try not to judge :balance_scale: me by my perspective :performing_arts:. Read about my purpose in life to know me better. . About Me . This browser does not support PDFs. Please download the PDF to view it: Download PDF. . &lt;/embed&gt; CV . Acknowledgements . This blog is also my self exploration into website building without knowing anything about websites. This learning experience was made possible into a live website thanks to these resources and people. . Jekyll, the static site-generator. | Github for free hosting. | Fastpages, Jupyter Notebooks to markdown converter with many other functionalities. (It’s great!) | Jekyll TOC | Jekyll-Codex | Dark mode | .",
          "url": "https://zshn25.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://zshn25.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}