{
  
    
        "post0": {
            "title": "Practicing Gratitude",
            "content": "I believe that most of us belong somewhere in the middle of this bell curve, which approximates how fortunate (in terms of many factors) people are. On one extreme are people who were born in extreme poverty without basic necessities, or with crippling physical and mental disabilities or during times of warfare and crisis or belonging to races/regions with extreme discrimination and injustice or have unfortunately undergone negative and life changing tragedies. On the other hand are the fortunate, with extreme amounts of wealth, health, freedom, luck, etc.. While most of us belong somewhere in the middle, we often question why are we not fortunate enough to be born in the richest, socially elite and forget than while belonging to the normal also means not belonging to the negative side. . . My hypothesis on how fortunate we are. X-axis: How fortunate we are. Y-axis: Population. Image by D Wells, CC BY-SA 4.0, via Wikimedia Commons. . This post is a reminder that while it’s not perfect, we should be grateful of being fortunate enough of not belonging to the extreme negative side. Let’s be grateful of our basic needs being fulfilled, of having access to food, clean water and shelter. Let’s be grateful to be born during such prosperous times with little conflicts and epidemics (except Covid-19). Let’s be grateful for having people who love and care for us, for the sacrifices many have suffered for our freedom and liberty to be who we want to be, to learn what we want to learn with access to unprecedented amount of knowledge the world has gathered for us and being able to live in the wonderful times where our personal freedoms are respected, where practicing equality is promoted and spreading of discrimination and hate is frowned upon. Let’s be grateful for being physically and mentally healthy without major disabilities and immediate access to world class healthcare and to not have undergone life crippling accidents/tragedies. Let’s be grateful for the world changing innovations happening in all fields every day. Let’s be grateful for this beautiful normal life. .",
            "url": "https://zshn25.github.io/practicing-gratitude/",
            "relUrl": "/practicing-gratitude/",
            "date": " • Apr 11, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Is convolution linear?",
            "content": "Discrete convolutions are characterized as matrix multiplications and are thus able to execute really fast on GPUs. But, how are they characterized as matrix multiplications? Are convolutions linear? Let’s find out. . 1. Definitions: . 1.1 Convolution . Let $f,g$ be two real valued functions in 1D $f,g : mathbb{R} to mathbb{R} $, the convolution of $f$ with $g$ is defined as . $f * g = displaystyle int_{ mathbb{R}} ! f(t) g(x-t) , mathrm{d}t$ . An example of the 1D convolution of a box function with itself can be seen in the example below . Convolution of a box function with itself. By Brian Amberg derivative work: Tinos, CC BY-SA 3.0. . 1.2 Linearity . Let $K$ be a mapping $K : A to B $ of two vector spaces $A,B$. Such a mapping is linear if . $K( alpha x+ beta y) = alpha K(x)+ beta K(y) $ . for all $ x in A, y in B$ and scalars $ alpha , beta in mathbb{R}$. . In simple words, a linear mapping/transformation preserves vector addition and scalar multiplication. It doesn’t matter whether the linear mapping is applied before or after vector addition and scalar multiplication. . . 2. Linearity of Convolution . To show that convolution is linear, for $ x,y,f : mathbb{R} to mathbb{R}, alpha , beta in mathbb{R}$, we need to prove . $( alpha x + beta y) * f stackrel{!}{=} alpha (x * f) + beta (y * f)$ . 2.1 Proof . (αx+βy)∗f=∫R ⁣(αx(t)+βy(t))f(x−t) dt=∫R ⁣(αx(t)f(x−t)+βy(t)f(x−t)) dt=α∫R ⁣x(t)f(x−t) dt+β∫R ⁣y(t)f(x−t) dt(Linearity of integral)=α(x∗f)+β(y∗f) large{ begin{aligned} ( alpha x + beta y) * f &amp;= int_{ mathbb{R}} ! ( alpha x(t) + beta y(t)) f(x-t) , mathrm{d}t &amp;= int_{ mathbb{R}} ! ( alpha x(t)f(x-t) + beta y(t)f(x-t)) , mathrm{d}t &amp;= alpha int_{ mathbb{R}} ! x(t)f(x-t) , mathrm{d}t + beta int_{ mathbb{R}} ! y(t)f(x-t) , mathrm{d}t quad text{(Linearity of integral)} &amp;= alpha( x * f) + beta( y * f) end{aligned} }(αx+βy)∗f​=∫R​(αx(t)+βy(t))f(x−t)dt=∫R​(αx(t)f(x−t)+βy(t)f(x−t))dt=α∫R​x(t)f(x−t)dt+β∫R​y(t)f(x−t)dt(Linearity of integral)=α(x∗f)+β(y∗f)​ . proves that convolution is a linear operator. This proof directly follows from that fact that an integral is a linear mapping of real-valued (integrable) functions to $ mathbb{R}$. . $ small{ displaystyle int_a^b{[{c_1}{f_1}(x)+{c_2}{f_2}(x)+ cdots +{c_n}{f_n}(x)]dx}={c_1} displaystyle int_a^b{f_1(x)dx}+{c_2} displaystyle int_a^b{f_2(x)dx}+ cdots +{c_n} displaystyle int_a^b{f_n(x)dx}}$ . . 3. Discrete convolution as matrix multiplication . So, if convolutions are linear, we should be able to express the discrete convolution as a matrix multiplication. In fact, one of the input function is converted to a Toeplitz matrix, enabling a discrete convolution to be characterized by a convolution. . y=h∗x=[h10⋯00h2h1⋮⋮h3h2⋯00⋮h3⋯h10hm−1⋮⋱h2h1hmhm−1⋮h20hm⋱hm−2⋮00⋯hm−1hm−2⋮⋮hmhm−1000⋯hm][x1x2x3⋮xn]y = h ast x = begin{bmatrix} h_1 &amp; 0 &amp; cdots &amp; 0 &amp; 0 h_2 &amp; h_1 &amp; &amp; vdots &amp; vdots h_3 &amp; h_2 &amp; cdots &amp; 0 &amp; 0 vdots &amp; h_3 &amp; cdots &amp; h_1 &amp; 0 h_{m-1} &amp; vdots &amp; ddots &amp; h_2 &amp; h_1 h_m &amp; h_{m-1} &amp; &amp; vdots &amp; h_2 0 &amp; h_m &amp; ddots &amp; h_{m-2} &amp; vdots 0 &amp; 0 &amp; cdots &amp; h_{m-1} &amp; h_{m-2} vdots &amp; vdots &amp; &amp; h_m &amp; h_{m-1} 0 &amp; 0 &amp; 0 &amp; cdots &amp; h_m end{bmatrix} begin{bmatrix} x_1 x_2 x_3 vdots x_n end{bmatrix}y=h∗x=⎣⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎡​h1​h2​h3​⋮hm−1​hm​00⋮0​0h1​h2​h3​⋮hm−1​hm​0⋮0​⋯⋯⋯⋱⋱⋯0​0⋮0h1​h2​⋮hm−2​hm−1​hm​⋯​0⋮00h1​h2​⋮hm−2​hm−1​hm​​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎤​⎣⎢⎢⎢⎢⎢⎢⎡​x1​x2​x3​⋮xn​​⎦⎥⎥⎥⎥⎥⎥⎤​ – Discrete convoliton using Toeplitz matrix . If this article was helpful to you, consider citing . @misc{suri_is-convolution-linear_2021, title={Is convolution linear?}, url={https://zshn25.github.io/is-convolution-linear/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={Mar}} .",
            "url": "https://zshn25.github.io/is-convolution-linear/",
            "relUrl": "/is-convolution-linear/",
            "date": " • Mar 11, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "ResNet feature pyramid in Pytorch",
            "content": ". Feature Pyramids are features at different resolutions. Since Neural Networks compute features at various levels, (for e.g. the earliest layers of a CNN produce low level features such as Edges and later layers produce higher level features) it would be great to use not only the higher level features but also the previous ones for further processing. . One of the application of such feature pyramid is to be used in an autoencoder architecture with skip connections from encoder to decoder like U-Net. . . In this example, we look at ResNet from Pytorch. ResNet is one of the earliest but also one of the best performing network architectures for various tasks. We inherit the ResNet class and write our own forward method to output a pyramid of feature maps instead. . class ResNetFeatures(ResNet): def __init__(self,**kwargs): super(ResNetFeatures,self).__init__(**kwargs) def _forward_impl(self, x: torch.Tensor) -&gt; List[torch.Tensor]: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x0 = self.relu(x) x = self.maxpool(x0) x1 = self.layer1(x) x2 = self.layer2(x1) x3 = self.layer3(x2) x4 = self.layer4(x3) return [x0,x1,x2,x3,x4] # returns features with channels [64,64,128,256,512] . That&#39;s it. Now, to use it, add it to the source of ResNet. I have made a Gist on how to do this here. Now you can give an argument features_only and it will return the feature pyramid as defined above. . Test code . ## This file is a modified version of [Pytorch&#39;s ResNet](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) and inherits it&#39;s licence. ## Author: Zeeshan Khan Suri import torch from torch import Tensor import torch.nn as nn try: from torch.hub import load_state_dict_from_url except ImportError: from torch.utils.model_zoo import load_url as load_state_dict_from_url from typing import Type, Any, Callable, Union, List, Optional __all__ = [&#39;ResNet&#39;, &#39;ResNetFeatures&#39;, &#39;resnet18&#39;, &#39;resnet34&#39;, &#39;resnet50&#39;, &#39;resnet101&#39;, &#39;resnet152&#39;, &#39;resnext50_32x4d&#39;, &#39;resnext101_32x8d&#39;, &#39;wide_resnet50_2&#39;, &#39;wide_resnet101_2&#39;] model_urls = { &#39;resnet18&#39;: &#39;https://download.pytorch.org/models/resnet18-5c106cde.pth&#39;, &#39;resnet34&#39;: &#39;https://download.pytorch.org/models/resnet34-333f7ec4.pth&#39;, &#39;resnet50&#39;: &#39;https://download.pytorch.org/models/resnet50-19c8e357.pth&#39;, &#39;resnet101&#39;: &#39;https://download.pytorch.org/models/resnet101-5d3b4d8f.pth&#39;, &#39;resnet152&#39;: &#39;https://download.pytorch.org/models/resnet152-b121ed2d.pth&#39;, &#39;resnext50_32x4d&#39;: &#39;https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth&#39;, &#39;resnext101_32x8d&#39;: &#39;https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth&#39;, &#39;wide_resnet50_2&#39;: &#39;https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth&#39;, &#39;wide_resnet101_2&#39;: &#39;https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth&#39;, } def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -&gt; nn.Conv2d: &quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot; return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation) def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -&gt; nn.Conv2d: &quot;&quot;&quot;1x1 convolution&quot;&quot;&quot; return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False) class BasicBlock(nn.Module): expansion: int = 1 def __init__( self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module] = None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(BasicBlock, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d if groups != 1 or base_width != 64: raise ValueError(&#39;BasicBlock only supports groups=1 and base_width=64&#39;) if dilation &gt; 1: raise NotImplementedError(&quot;Dilation &gt; 1 not supported in BasicBlock&quot;) # Both self.conv1 and self.downsample layers downsample the input when stride != 1 self.conv1 = conv3x3(inplanes, planes, stride) self.bn1 = norm_layer(planes) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(planes, planes) self.bn2 = norm_layer(planes) self.downsample = downsample self.stride = stride def forward(self, x: Tensor) -&gt; Tensor: identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = self.relu(out) return out class Bottleneck(nn.Module): # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2) # while original implementation places the stride at the first 1x1 convolution(self.conv1) # according to &quot;Deep residual learning for image recognition&quot;https://arxiv.org/abs/1512.03385. # This variant is also known as ResNet V1.5 and improves accuracy according to # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch. expansion: int = 4 def __init__( self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module] = None, groups: int = 1, base_width: int = 64, dilation: int = 1, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(Bottleneck, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d width = int(planes * (base_width / 64.)) * groups # Both self.conv2 and self.downsample layers downsample the input when stride != 1 self.conv1 = conv1x1(inplanes, width) self.bn1 = norm_layer(width) self.conv2 = conv3x3(width, width, stride, groups, dilation) self.bn2 = norm_layer(width) self.conv3 = conv1x1(width, planes * self.expansion) self.bn3 = norm_layer(planes * self.expansion) self.relu = nn.ReLU(inplace=True) self.downsample = downsample self.stride = stride def forward(self, x: Tensor) -&gt; Tensor: identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) out = self.relu(out) out = self.conv3(out) out = self.bn3(out) if self.downsample is not None: identity = self.downsample(x) out += identity out = self.relu(out) return out class ResNet(nn.Module): def __init__( self, block: Type[Union[BasicBlock, Bottleneck]], layers: List[int], num_classes: int = 1000, zero_init_residual: bool = False, groups: int = 1, width_per_group: int = 64, replace_stride_with_dilation: Optional[List[bool]] = None, norm_layer: Optional[Callable[..., nn.Module]] = None ) -&gt; None: super(ResNet, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d self._norm_layer = norm_layer self.inplanes = 64 self.dilation = 1 if replace_stride_with_dilation is None: # each element in the tuple indicates if we should replace # the 2x2 stride with a dilated convolution instead replace_stride_with_dilation = [False, False, False] if len(replace_stride_with_dilation) != 3: raise ValueError(&quot;replace_stride_with_dilation should be None &quot; &quot;or a 3-element tuple, got {}&quot;.format(replace_stride_with_dilation)) self.groups = groups self.base_width = width_per_group self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = norm_layer(self.inplanes) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]) self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]) self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512 * block.expansion, num_classes) for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming_normal_(m.weight, mode=&#39;fan_out&#39;, nonlinearity=&#39;relu&#39;) elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)): nn.init.constant_(m.weight, 1) nn.init.constant_(m.bias, 0) # Zero-initialize the last BN in each residual branch, # so that the residual branch starts with zeros, and each residual block behaves like an identity. # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677 if zero_init_residual: for m in self.modules(): if isinstance(m, Bottleneck): nn.init.constant_(m.bn3.weight, 0) # type: ignore[arg-type] elif isinstance(m, BasicBlock): nn.init.constant_(m.bn2.weight, 0) # type: ignore[arg-type] def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int, stride: int = 1, dilate: bool = False) -&gt; nn.Sequential: norm_layer = self._norm_layer downsample = None previous_dilation = self.dilation if dilate: self.dilation *= stride stride = 1 if stride != 1 or self.inplanes != planes * block.expansion: downsample = nn.Sequential( conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion), ) layers = [] layers.append(block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer)) self.inplanes = planes * block.expansion for _ in range(1, blocks): layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer)) return nn.Sequential(*layers) def _forward_impl(self, x: Tensor) -&gt; Tensor: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = torch.flatten(x, 1) x = self.fc(x) return x def forward(self, x: Tensor) -&gt; Tensor: return self._forward_impl(x) class ResNetFeatures(ResNet): def __init__(self,**kwargs): super(ResNetFeatures,self).__init__(**kwargs) def _forward_impl(self, x: torch.Tensor) -&gt; torch.Tensor: # See note [TorchScript super()] x = self.conv1(x) x = self.bn1(x) x0 = self.relu(x) x = self.maxpool(x0) x1 = self.layer1(x) x2 = self.layer2(x1) x3 = self.layer3(x2) x4 = self.layer4(x3) return [x0,x1,x2,x3,x4] # returns features with channels [64,64,128,256,512] def _resnet( arch: str, block: Type[Union[BasicBlock, Bottleneck]], layers: List[int], pretrained: bool, progress: bool, features_only = False, **kwargs: Any ): if features_only: model = ResNetFeatures(block=block, layers=layers, **kwargs) else: model = ResNet(block, layers, **kwargs) if pretrained: state_dict = load_state_dict_from_url(model_urls[arch], progress=progress) model.load_state_dict(state_dict) return model def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-18 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet18&#39;, BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs) def resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-34 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet34&#39;, BasicBlock, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-50 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet50&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-101 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet101&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) def resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNet-152 model from `&quot;Deep Residual Learning for Image Recognition&quot; &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; return _resnet(&#39;resnet152&#39;, Bottleneck, [3, 8, 36, 3], pretrained, progress, **kwargs) def resnext50_32x4d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNeXt-50 32x4d model from `&quot;Aggregated Residual Transformation for Deep Neural Networks&quot; &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;groups&#39;] = 32 kwargs[&#39;width_per_group&#39;] = 4 return _resnet(&#39;resnext50_32x4d&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def resnext101_32x8d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;ResNeXt-101 32x8d model from `&quot;Aggregated Residual Transformation for Deep Neural Networks&quot; &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;groups&#39;] = 32 kwargs[&#39;width_per_group&#39;] = 8 return _resnet(&#39;resnext101_32x8d&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) def wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;Wide ResNet-50-2 model from `&quot;Wide Residual Networks&quot; &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048 channels, and in Wide ResNet-50-2 has 2048-1024-2048. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;width_per_group&#39;] = 64 * 2 return _resnet(&#39;wide_resnet50_2&#39;, Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs) def wide_resnet101_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -&gt; ResNet: r&quot;&quot;&quot;Wide ResNet-101-2 model from `&quot;Wide Residual Networks&quot; &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_. The model is the same as ResNet except for the bottleneck number of channels which is twice larger in every block. The number of channels in outer 1x1 convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048 channels, and in Wide ResNet-50-2 has 2048-1024-2048. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet progress (bool): If True, displays a progress bar of the download to stderr &quot;&quot;&quot; kwargs[&#39;width_per_group&#39;] = 64 * 2 return _resnet(&#39;wide_resnet101_2&#39;, Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs) . . model = resnet18(pretrained=True, features_only=True) features = model(torch.randn((1,3,265,265))) [print(f.shape) for f in features] . If this article was helpful to you, consider citing . @misc{suri_ResNet-feature-pyramid-in-Pytorch_2021, title={ResNet feature pyramid in Pytorch}, url={https://zshn25.github.io/ResNet-feature-Pyramid-in-Pytorch/}, journal={Curiosity}, author={Suri, Zeeshan Khan}, year={2021}, month={Mar}} .",
            "url": "https://zshn25.github.io/ResNet-feature-pyramid-in-Pytorch/",
            "relUrl": "/ResNet-feature-pyramid-in-Pytorch/",
            "date": " • Feb 9, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "$GME short squeeze",
            "content": ". This week (starting 25/01/2021) is an exciting event in the history of stocks, where rare events happening to the GME stock. Although, this might be a definite opportunity to make/lose money, I am in it for the knowledge of how the stock market works. As I am trying to figure out this event and learn more about options trading, I came across this comment which explains things so clearly that I decided to share it here, for my future reference on options knowledge and also to give my readers an insight. . On the question, what is going on with GME, this following comment explains the situation in ELI5 terms . Comment from discussion All right WTF is going on with GME. Many people shorted. To hedge their shorts (since GME is sky-rocketing already), they will need to buy shares. But, since there are only limited shares available, this will drive the price more up, adding more pressure on other short sellers. This cycle repeats and is called the short squeeze. . Some keywords to understand . Shorting or short selling is when you bet your money on the stock declining. You sell shares at the current market price and you believe the share’s value decreases, you’ve sold high. Now, what if you don’t already own any shares? You can borrow shares (from the market), by making the market buy it from you in some future date. Where will you have it in the future? You buy it from the market’s future price (which you believe to be lower than current price) and hence have made money. . Many short sellers have borrowed GME shares, speculating it to crash and sold these borrowed shares to the market. Now, there are only limited shares available and due to heavy short selling, the (borrowed) shares are not actually available. . Companies which have already shorted, (predicted that the stock will go down) but since the opposite is happening (GME has sky rocketed to ATH since people have shorted), the short sellers will buy GME stock to reduce their future losses (or, reduce risk). This is called hedging. . The same user further explains with an example why the market makers (MM) would buy . Comment from discussion All right WTF is going on with GME. What to do? . This is a rare event where normal people like us can coordinate and take money for MM. I do not advice to do anything. Do your own DD, but I have bought some position today at open and hoping the squeeze to happen. Note that short squeeze could take days to happen. And the next question is, when to sell? Very good question. Nobody knows. Depending on your apatite for loss, you can wait for it to truly rocket or take whatever gains without FOMO on future gains. . Edit 1 26/01/2021 . Today we have seen another gamma squeeze where GME rose till $155 (over 100%) but at the end of the day, GME came down, closing at +20%. What drove the price down was believed to be a short ladder attack, where a short seller sells to another short seller and within a short time, the other short seller sells it back. What this does is make people think that other shareholders are selling at lower price, thus creating a havoc and making some of the investors sell at lower price. . GME - How shorts manipulated you, and how you can be better from r/wallstreetbets Edit 27/01/2021 . . Yesterday we have seen yet another gamma squeeze but this time it did not drop back. It was amazing to see GME rise by so much after hours. Maybe it was due to Elon Musk’s tweet? . Gamestonk!! https://t.co/RZtkDzAewJ . &mdash; Elon Musk (@elonmusk) January 26, 2021 The Endgame strategy? . GME Endgame from r/wallstreetbets Final Edit: . GME peaked at $450 as the result of the squeeze. Many brokers including the famous Robinhood in the US halted trading on GME. That means, no one was allowed to buy GME shares anymore. Only selling was allowed. As a result, the price fell from there. Many analysts later said that it GME wouldn’t be halted, it would indeed reach $1000. . . I use Trading212 for buying stocks, which does not charge any commission or any order fee. We both can get a free stock share worth up to €100 if you use the following link to sign up. Do not forget to deposit at least 1€ after signing up. Create a Trading 212 Invest account using this link https://www.trading212.com/invite/FzPJYhiT and we both get a free share! If you already have an account, you can try my Promo Code FzPJYhiT to get a free share. . Disclaimer: This is not a financial advice. Do your own DD before investing. .",
            "url": "https://zshn25.github.io/gme-stock/",
            "relUrl": "/gme-stock/",
            "date": " • Jan 25, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Hot chocolate",
            "content": "I once visited a local Café and ordered Hot Chocolate. Didn’t expect much of it and thought it would be one of those powdered ready-made Cocoa mix. I was pleasantly surprised by how delicious this hot chocolate was. So, I decided to make such hot chocolate myself and looked for recipes. But I couldn’t find any raw Cacao without sugar. The 100% chocolates I could found after a lot of searching are . . Fig. 1: 100% chocolates I found on Amazon but the Sevenhills Cacao Mass is much cheaper. [Disclaimer] . Ingredients . Cacao | Milk | Cream | Spices (Optional) | Orange Zest (Optional) | Sugar or other sweeteners (Optional) | . Recipe . Take around 5 pieces of cacao mass. . . | Add the cacao and heavy cream to a bowl on medium heat. The high fat in the heavy cream makes the Cacao flavor come out . . | Stir with a spoon (preferably wooden to not destroy the non-stick bowl) until it looks like this. At this point you have very thick Keto hot chocolate (more like a pudding) and you can already consume it this way. . . | For the drink, add milk while continuing to stir . . | Add a pinch of Chilli, 3 pinches of Cinnamon powder or one stick, 2 pinches of Cardamom or 2 pods and 3 Cloves. You can also add Orange Zest for a true mulled chocolate feeling. You can also optionally add sugar or any other sweeteners, depending on your taste. . . | Let it simmer on low heat while stirring once in a while. The longer you leave it simmer, the thicker the hot chocolate becomes. . . | Enjoy!! . | Disclaimer: Amazon affiliate links .",
            "url": "https://zshn25.github.io/hot-chocolate/",
            "relUrl": "/hot-chocolate/",
            "date": " • Jan 23, 2021"
        }
        
    
  
    
  
    
        ,"post6": {
            "title": "Privacy",
            "content": "Why it matters? . Why should you care? . Many people ask me why should they care about their own privacy. It’s not like they have anything to hide. That might be true. . But, why should allowing people look at you be the default? Would you be comfortable to let anyone come into your home, install cameras to let the whole world have access to your lives? Would you keep your house doors unlocked? . Probably not. Even if you are not doing anything wrong in your houses. So, why would you let them look at your life all the time through your virtual windows? It is not that there is something to hide. It is why would I want my private life to be public? . Privacy speaks freedom. . Humans are social beings. We care about what others think of us. We try to adjust our behavior depending on the social norms and others’ feedback. Imagine yourself in the middle of a busy street full of people. Would you be as free as you would be in your house all by yourself? Probably not. Not only humans change their behavior in others presence but also the possibility of someone being present changes our behavior. You are your true self when nobody’s looking and nobody could be looking; because you have the freedom to be so. You don’t have to constantly adjust yourself in the fear of being judged. . Privacy brings freedom. I am free to have my life private, to have a pay where I can go and be free of the judgmental eyes. I am free to allow whomever I want (or no one at all) to monitor me. To be able to live freely as if no one is looking. To be my true self. . That freedom is taken away when privacy is taken away ( for e.g., via surveillance). Institutions want to be in control and the most effective way of being in control is to take away freedom. To force compliance of social norms and orthodoxy. To brainwash the members into believing what they want them to believe. . **Side note**: Freedom as a virtue, frees one from the social norms and orthodoxies and nourishes creative open thinking. . What’s the worst that could happen? . The world is full of ill-intended malicious people who wouldn’t mind destroying someone else’s life for their own benefit. All it takes is one mistake from innocent people being in the wrong place at the wrong time to screw them over. . Your information may end-up in a data breach with some foreign . Your information may be used against you by your government in order to gain political power. Think about the social credit system. It is already being practiced in some countries. For e.g., let’s say your country implements it and starts surveilling on you 24x7 and as an open-minded individual, you enter a discussion with your peers and talk against some things your government has done recently. There is a good chance that because once-upon-a-time you raised your voice against the government, you are denied flight tickets for your next vacation. . This again brings up my point on personal freedom. Privacy speaks freedom. The ability to criticize the government is the exact thing that keeps them in check. Taking away that ability by penalizing free speech takes away our freedom and restricts us . The privacy paradox . Many people are indeed concerned about their privacy but behave as they didn’t. This is known as the privacy paradox. . Humans are social beings and we seek others’ approval. We have a need for others to know what we are doing, which is why we voluntarily publish information about us online. But as social beings, we also need to acknowledge that there are things which let our close ones, our psychologists, our physicians, our lawyers to know about us which we would never be willing others know. People easily say they don’t value privacy while their actions negate their belief. . Other reasons for the privacy paradox might be “finding it technologically difficult to take certain actions that disallow institutions to take advantage of it. Applications are purposefully designed to make it as difficult for a regular user as possible to care about their privacy by changing the default settings, which are often extracting as much of user’s personal data as possible. Most users do not have the knowledge and experience to protect themselves. . What can you do? . https://chrome.google.com/webstore/detail/google-analytics-opt-out/fllaojicojecljbmefodhfapmkghcbnh/related?hl=en . Closing thoughts . To summarize, I would like to point you to the following TED talk which will hopefully fill-in the gaps I left unfilled. .",
            "url": "https://zshn25.github.io/why-privacy-matters/",
            "relUrl": "/why-privacy-matters/",
            "date": " • Jan 9, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "How to Release on Github",
            "content": "To release on Git, you need to tag a commit first. . Tagging a commit . A tag is a label attached to a specific commit. There are two types of tags . Lightweight | Annotated | . git tag command is used to view all tags in the repo. . Lightweight tag . The lightweight tag is a simple reference to a commit. . git tag &lt;tagname&gt; &lt;commit&gt; creates a lightweight tag. If &lt;commit&gt; is optional and defaults to HEAD. . Example . $ git tag v0.1 HEAD^ # tag the previous commit $ git tag # view all tags v0.1 $ git tag v1.0 # tag the current commit $ git tag # view all tags v0.1 v1.0 . Annotated tag . The annotated tag is a full git object which includes additional (annotated) information such as tag author info, tag date, tag message and tag commit ID. In general, annotated tags are recommended over lightweight . To tag a commit with an annotated tag, use the git tag command with -a option. You must also specify a message using -m option . Example . $ git tag -a -m &quot;feature release 1.0&quot; v1.0 . Pushing tags . git push does not automatically push the tags to remote repository. . To transfer a single tag, use git push &lt;remote&gt; &lt;tagname&gt; | . | To transfer all tags, use git push &lt;remote&gt; --tags | . | . Releases . Once you tag a commit, you can use this to create a release. On GitHub, you can create a release by following this tutorial .",
            "url": "https://zshn25.github.io/how-to-release-on-git/",
            "relUrl": "/how-to-release-on-git/",
            "date": " • Nov 8, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Nutrition",
            "content": "Preventing disease is the first step to long-term health and well-being. By following basic nutrition advice you can improve your health by significant amounts. . . Nutrition is not a solved problem. We still don’t know for sure which foods to eat and which ones to avoid but there is a decades of consistent science and research, which I want to bring to you. Take it with a grain of salt Obesity as a worldwide public health crisis . Western diet is now a major cause of obesity, which is a recognized chronic disease with well-defined health consequences such as Cardiovascular diseases, type 2 diabetes, obstructive sleep apnea, certain types of cancer, osteoarthritis, depression 1. Obesity is labelled by the WHO as a worldwide public health crisis 2. Western diet is normally defined as highly processed foods with very little whole grains, fruits and vegetables. The rate at which obesity is increasing is also increasing at an alarming rate. Data shows that 39% of adults aged 18 years and older were overweight or obese in 20163. . Fig. 1: Obesity is increasing worldwide at an alarming rate. Source . The need to be aware of nutrition in order to avoid obesity and stay healthy now is more than ever. Controlling our food behavior is essential to our long term well being. . Why is obesity increasing? . We are increasingly outsourcing our food preparation. Convenient food has become a norm. These fast-food is often designed as snack-food and marketed to be eaten continuously throughout the day. Such foods are not only less healthy, very high in salt, trans-fat and sugar, but we also tend to overeat them. . This is not an ad. As seen in the above commercial, nutrient dense foods tend to spoil fast while processed foods usually have very low nutrients in order to increase their shelf life (even pests don’t want to eat processed food). The refining process removes important nutrients such as fiber, iron, B vitamins, in order to increase the food’s shelf life. Their business model is to use the cheapest available raw ingredients, process it as much as possible to increase shelf life and add large amounts salt, fat and sugar to make them seem attractive. . . Focus on food rather than nutrients . We have all been taught that food is made up of 3 macronutrients . Carbohydrates | Proteins | Fats | . Historically, food was a scarce resource. In the animal kingdom, presence of food was unpredictable. So, we evolved to store food in the body for later use. All calories (including proteins, carbs and fats) that aren’t converted into usable energy, ATP, are stored in the body in the form of adipose tissue for later use. This is what we call body fat. It is not necessarily bad to have body fat but if you have excess of body fat, it can lead to severe long term-health issues. . . Fig.2: Obesity and BMI. BruceBlaus, CC BY-SA 4.0, via Wikimedia Commons &lt;/sup&gt; . Is dietary fat really bad? . To address obesity, a lot of focus on reducing saturated fats in diets were made. The processed food industry responded by supplementing fat with sugar to make the food seem more appealing. This also increased the shelf life of foods and so almost every packaged food now comes with enormous amounts of sugar and other sweeteners. This fueled our modern obesity and diabetes. . Despite of an enormous increase in the supply of fat-free foods, obesity rates continued to rise. It is important to know the difference between good and bad fats . The good, the bad, and the ugly . Unsaturated fats, such as Omega-3 fatty acids, which are found in fish and some nuts,seeds, are good for long term health. In fact, Omega-3 fatty acids are the only kinds which cannot be made in human body. So, it is essential to have them. . | Saturated fats are bad for health 4. They increase the amound of bad chelestrol in the blood (LDL). . | While naturally occurring unsaturated fats, such as the ones found in olive oil, avocado, fish and nuts are good, chemically engineered saturated fats, such as the ones found in margarines and frying oils have week chemical bonds and are easily converted into trans-fats 5. Trans fats increase the amount of bad cholesterol in the blood (LDL) and decreases the amount of good cholesterol (HDL), which increases the risk of heart disease 6. These must be avoided as much as possible. . | . Are carbohydrates really bad? . A lot of recent focus has been on the fact that we overconsume carbohydrates. A lot of popular diet trends encourage us to drastically reduce carbs from our diet, even to the extend of avoiding fresh fruits and even grains. At the same time, they seem to suggest that high intake of proteins and fats can be eaten freely. But, a diet with high amounts of animal protein and no whole grains, fruits could leave us with serious problems in the long run. . Carbs has a large variety of foods, some of which are very important for our health, such as brown rice, rolled oats which are rich in fiber; and some are are bad for our health, such as corn-syrup, which has no fiber. In general, the lower the glycemic index (GI) of the carbohydrate, the better. A list of low, medium and bad carbs w.r.t GI is mentioned here. . What about proteins? . All proteins are not created equal. Plant based proteins contain more fiber and less saturated fat than animal based proteins. People who eat lots of plant based diet, have much better health and longevity than people who eat heavy meat diet 7. A diet high in poor quality animal protein, such as processed meat, and high fat cuts, can be harmful to health. Processed meats tend to have very high amounts of sodium, which is a contributor to high blood pressure. . Thinking of food as a whole and not as macronutrients . Categorizing foods into these basic micronutrients may be helpful to study foods but it is not helpful to communicate about them. Food is much more complex than just these macronutrients. So, rather than focusing on nutrients, we should focus on food, because ultimately we don’t eat nutrients but food. . Key takeaways: . The quality of the source of nutrients matters a lot for long term health. . Eat naturally occurring unsaturated fats, such as avocado, olive oil, nuts | low GI carbs with lots of fiber | plant-based proteins. | . | Reduce saturated fats, such as red meat | medium GI carbs with less fiber | animal based proteins. | . | Avoid trans fats, such as oils used for frying in fast food restaurants | refined sugar and carbohydrates with high GI | processed meats | . | . . Exercise . eating --&gt; energy++ excercizing --&gt; energy-- . For people who are trying to lose excess weight, favoring energy expenditure over energy storage needs to be prioritized. This can be achieved by consuming fewer calories and exercising more. . But, not only the quantity of the food, but also the quality of the food we eat matters. . . Summary . When we outsource our food preparation to large companies or restaurants, we get low nutrient dense food. . Nutrient density=nutrients per gramcalories per gram text{Nutrient density} = frac{ text{nutrients per gram}}{ text{calories per gram}}Nutrient density=calories per gramnutrients per gram​ . Home-made food, cooked using high quality ingredients, having natural unsaturated fats, low GI, lots of fiber, and mostly plant-based protein will lead to good long-term health and longevity. The following food pyramid summaries this in a graphical, easy to remember illustration. . . Fig.3: Food pyramid. Spmallare, CC BY 3.0, via Wikimedia Commons . Even if you’re not obese, being aware of the food you eat and maintaining physical exercise will ensure long term health. . . References . https://en.wikipedia.org/wiki/Obesity#Effects_on_health &#8617; . | Hurt RT, Kulisek C, Buchanan LA, McClave SA. The obesity epidemic: challenges, health initiatives, and implications for gastroenterologists. Gastroenterol Hepatol (N Y). 2010;6(12):780-792. &#8617; . | WHO (2018) – Fact sheet – Obesity and overweight. Updated February 2018 &#8617; . | https://en.wikipedia.org/wiki/Fat#Cis_and_trans_fats &#8617; . | https://en.wikipedia.org/wiki/Saturated_fat#Association_with_diseases &#8617; . | https://www.webmd.com/diet/guide/understanding-trans-fats &#8617; . | https://www.health.harvard.edu/blog/eat-more-plants-fewer-animals-2018112915198 &#8617; . |",
            "url": "https://zshn25.github.io/nutrition/",
            "relUrl": "/nutrition/",
            "date": " • Oct 30, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": ":wave: Welcome to Curiosity :tm: . My name is Zeeshan Khan Suri. I believe in life long learning :mortar_board:, I yearn for knowledge :books: and I seek :eyes: the truth :microscope:. In Curiosity, I plan to document :pencil: my journey :roller_coaster: towards this goal :dart:, for that is what that matters in the end :rocket:. Be open minded :haircut_woman:, humble :speak_no_evil: (like myself :stuck_out_tongue_winking_eye:) and try not to judge :balance_scale: me by my perspective :performing_arts:. .",
          "url": "https://zshn25.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://zshn25.github.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}